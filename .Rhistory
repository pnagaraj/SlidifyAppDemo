segmentationOriginal$Case[[2]]
segmentationOriginal$Case[[3]]
segmentationOriginal$Case[[4]]
segmentationOriginal$Case[[400]]
segmentationOriginal$Case[[401]]
segmentationOriginal$Case[[402]]
segmentationOriginal$Case[[1:4]]
segmentationOriginal$Case[[]][1]
segmentationOriginal$Case
idx=isTRUE(segmentationOriginal$Case==Test)
idx=isTRUE(segmentationOriginal$Case=="Test")
idx
idx=(segmentationOriginal$Case=="Test")
idx
idx=which(segmentationOriginal$Case=="Test")
idx
idx=which(segmentationOriginal$Case=="Train")
idx=which(segmentationOriginal$Case=="Test")
names(segmentationOriginal)
?train
training=segmentationOriginal[idx]
training=segmentationOriginal[idx,]
testing=segmentationOriginal[-idx,]
modfit=train(method="rpart",data=training)
str(segmentationOriginal$Class)
modfit=train(Class~.,method="rpart",data=training)
?predict
ndata=data.frame(TotalIntech2=23000, FiberWidthCh1=10,PerimStatusCh1=2)
ndata
predict(modfit,ndata)
testing$TotalIntenCh2
which(testing$TotalIntenCh2==23000)
str(segmentationOriginal$Cell)
help(segmentationOriginal)
predict(modfit,ndata)
modfit
which(testing$TotalIntenCh2>23000)
which(testing$TotalIntenCh2<23000)
which(testing$TotalIntenCh2>23000)
print(modfit$finalModel)
pred=predict(modFit,newdata=testing)
pred=predict(modfit,newdata=testing)
print(pred$finalModel)
print(modFit$finalModel)
print(modit$finalModel)
print(modfit$finalModel)
source('~/Documents/coursera/practicalmachinelearning/quizweek3.R')
install.packages("rattle")
library(rattle)
fancyRpartPlot(modfit$finalModel)
library(rpart)
fancyRpartPlot(modfit$finalModel)
fancyRpartPlot(modfit$finalModel)
source('~/Documents/coursera/practicalmachinelearning/quizweek3.R')
source('~/Documents/coursera/practicalmachinelearning/quizweek3.R')
plot(modfit$finalModel,uniform=TRUE)
text(modfit$finalModel,use.n=TRUE,all=TRUE)
source('~/Documents/coursera/practicalmachinelearning/quizweek3.R')
source('~/Documents/coursera/practicalmachinelearning/quizweek3.R')
source('~/Documents/coursera/practicalmachinelearning/quizweek3.R')
data(olive)
olive=olive[,-1]
#These data contain information on 572 different Italian olive oils from multiple regions in Italy. Fit a classification tree where Area is the outcome variable. Then predict the value of area for the following data frame using the tree command with all defaults
modFit=train(Area~.,method="rpart",data=olive)
print(modFit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newdata=newdata)
print(modFit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
?predict
predict(modFit,newdata=newdata)
help(olive)
str(olive)
?tree
?Tree
plot(modFit$finalModel,uniform=TRUE)
text(modFit$finalModel,use.n=TRUE,all=TRUE)
qplot(Eicosenoic,Linoleic,colour=Area,data=newdata)
library(ggplot2)
qplot(Eicosenoic,Linoleic,colour=Area,data=newdata)
qplot(Eicosenoic,Linoleic,colour=Area,data=olive)
olive$Area
?train
library(mlbench)
library(m1bench)
data(BostonHousing)
data(iris)
str(iris)
data(olive)
olive=olive[,-1]
#These data contain information on 572 different Italian olive oils from multiple regions in Italy. Fit a classification tree where Area is the outcome variable. Then predict the value of area for the following data frame using the tree command with all defaults
modFit=train(is.factor(Area)~.,method="rpart",data=olive)
print(modFit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newdata=newdata)
data(olive)
olive=olive[,-1]
#These data contain information on 572 different Italian olive oils from multiple regions in Italy. Fit a classification tree where Area is the outcome variable. Then predict the value of area for the following data frame using the tree command with all defaults
modFit=train(as.factor(Area)~.,method="rpart",data=olive)
print(modFit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newdata=newdata)
qplot(Palmitoleic,Linoleic,colour=Area,data=olive)
plot(modFit$finalModel,uniform=TRUE)
text(modFit$finalModel,use.n=TRUE,all=TRUE)
data(olive)
olive=olive[,-1]
#These data contain information on 572 different Italian olive oils from multiple regions in Italy. Fit a classification tree where Area is the outcome variable. Then predict the value of area for the following data frame using the tree command with all defaults
modFit=train(Area~.,method="rpart",data=olive)
print(modFit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newdata=newdata)
plot(modFit$finalModel,uniform=TRUE)
text(modFit$finalModel,use.n=TRUE,all=TRUE)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
str(trainSA)
?train
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
# set seed to 13234 , fit a logistic regression (method=glm, family="binomial")
# chd (coronary heart disease is the outcome)
# predictors age at onset, current alcohol consumption, obesity levels, cumulative tabacco, type-A behavior, and low density lipoprotein cholesterol
set.seed(13234)
modFit=train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=trainSA)
prediction=predict(modFit,testSA)
prediction
table(prediction,testSA$chd)
modFit
modFit$finalModel
source('~/Documents/coursera/practicalmachinelearning/quizweek3.R')
source('~/Documents/coursera/practicalmachinelearning/quizweek3.R')
library("AppliedPredictiveModeling")
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
library(rattle)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
# set seed to 13234 , fit a logistic regression (method=glm, family="binomial")
# chd (coronary heart disease is the outcome)
# predictors age at onset, current alcohol consumption, obesity levels, cumulative tabacco, type-A behavior, and low density lipoprotein cholesterol
set.seed(13234)
modFit=train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=trainSA)
prediction=predict(modFit,testSA)
values=testSA$chd
values
prediction
values
str(values)
str(prediction)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
misClass
missClass
source('~/Documents/coursera/practicalmachinelearning/quizweek3.R')
missClass(trainSA$chd,prediction)
missClass(testSA$chd,prediction)
source('~/Documents/coursera/practicalmachinelearning/quizweek3.R')
missClass(trainSA$chd,predict(modFit,trainSA))# training misfit
missClass(testSA$chd,predict(modFit,testSA))#testing misfit
?train
?varImp
data(vowel.train)
data(vowel.test)
# set the var y to be a factor variable in both data. Set the seed to 33833. Fit a random forest predictor relating the factor variable y to the remaining vars.
vowel.train$y = as.factor(vowel.train$y)
vowel.test$y = as.factor(vowel.test$y)
set.seed(33833)
modFit=train(y~.,method="rf",data=vowel.train)
modFit=train(y~.,method="rf",data=vowel.train)
varImp(modFit)
source('~/Documents/coursera/practicalmachinelearning/quizweek4.R')
source('~/Documents/coursera/practicalmachinelearning/quizweek4.R')
source('~/Documents/coursera/practicalmachinelearning/quizweek4.R')
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
# set y to be a factor variable in both training and test data
vowel.train$y = is.factor(vowel.train$y)
vowel.test$y = is.factor(vowel.test$y)
# set seed to 33833
set.seed(33833)
modfit1=train(y~.,data=vowel.train,method="rf",prox=TRUE)
# 2. fit a boosted predictor using the "gbm" method
modfit2=train(y~.,data=vowel.train,method="gbm")
modfit1=train(y~.,data=vowel.train,method="rf")
source('~/Documents/coursera/practicalmachinelearning/quizweek4.R')
modfit1=train(y~.,data=vowel.train,method="rf")
# 2. fit a boosted predictor using the "gbm" method
modfit2=train(y~.,data=vowel.train,method="gbm")
modfit1=train(y~.,data=vowel.train,method="rf",prox=TRUE)
modfit2=train(y~.,data=vowel.train,method="gbm",verbose=FALSE)
pred1=predict(modfit1,vowel.test)
pred2=predict(modfit2,vowel.test)
pred
pred1
table(pred1,vowel.test$y)
?accuracy
pred1
nmissClass = function(values,pred1){sum(((pred1)*1) == values)/length(values)}
nmissClass(vowel.test$y,predict(modfit1,vowel.test))# correct clasification by model 1
nmissClass(vowel.test$y,predict(modfit2,vowel.test))# model 2
modfit1
nmissClass = function(values,prediction){sum(((prediction)*1) == values)/length(values)}
nmissClass(vowel.test$y,predict(modfit1,vowel.test))# correct clasification by model 1
nmissClass(vowel.test$y,predict(modfit2,vowel.test))# model 2
nmissClass = function(values,prediction){sum(prediction == values)/length(values)}
nmissClass(vowel.test$y,predict(modfit1,vowel.test))# correct clasification by model 1
nmissClass(vowel.test$y,predict(modfit2,vowel.test))# model 2
source('~/Documents/coursera/practicalmachinelearning/quizweek4.R')
data2=vowel.test[pred1==pred2]
data2=vowel.test[pred1==pred2,]
data2
pred1
data2
nmissClass = function(values,prediction){sum(prediction == values)/length(prediction)}
nmissClass(vowel.test$y,predict(modfit1,vowel.test))# correct clasification by model 1
nmissClass(vowel.test$y,predict(modfit2,vowel.test))# model 2
# combined model
data3=vowel.test[pred1==pred2,] # read rows whose predictions are the same
pred3=predict(modfit1,data3)# predict classes for data3. These are cases where the rf and gbm methods gave same results. Therefore can use modfit1 or modfit2 as the model.
nmissall=sum(pred3==data3$y)/length(pred3)
nmissall
pred3a=predict(modfit2,data3)
nmissall = sum(pred3a==data3$y)/length(pred3)
nmissall
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
# predict diagnosis with all the other vars using rf, gbm and lda models.
modfit1=train(diagnosis~.,data=training,method="rf")
modfit2=train(diagnosis~.,data=training,method="gbm",verbose=FALSE)
modfit3=train(diagnosis~.,data=training,method="lda")
pred1=predict(modfit1,testing)
pred2=predict(modfit2,testing)
pred3=predict(modfit3,testing)
# predall
predDF=data.frame(pred1,pred2,pred3,diagnosis=testing$diagnosis)
# combine or stack models using random forest
comb = train(diagnosis~.,method="rf",data=predDF)
combpred = predict(comb,predDF)
# what is the resulting accuracy on the test set? is it better or worse than each of the individual prediction?
nmiss_rf=sum(pred1==testing$diagnosis)/length(pred1)
nmiss_gbm=sum(pred2==testing$diagnosis)/length(pred2)
nmiss_lda=sum(pred3==testing$diagnosis)/length(pred3)
nmiss_comb=sum(combpred==testing$diagnosis)/length(combpred)
nmiss_rf
nmiss_gbm
nmiss_lda
nmiss_comb
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
str(testing)
modfit=train(CompressiveStrength~.,data=concrete,method="lasso")
modfit=train(CompressiveStrength~.,data=concrete,method="lasso")
modfit
?train
?plot.enet
modfit$Final
str(modfit)
modfit$finalModel
str(testing)
modfit$modelinfo
modfit$modelInfo
modfit$coefnames
modfit$control
model.lasso=lars(CompressiveStrength~.,data=concrete,type="lasso")
predict(modfit,data=testing)
predict(modfit,data=testing)$coef
predict(modfit,data=testing,type="coefficient")$coef
str(training)
modfit=train(CompressiveStrength~.,data=concrete,method="lasso")
predict(modfit,training)$coef
?predict
predict(modfit$finalModel,s=modfit$bestTune$.fraction,type="coefficients",mode="fraction")$coef
predict(modfit$finalModel,s=modfit$bestTune,type="coefficients",mode="fraction")$coef
predict(modfit$finalModel,type="coefficients")$coef
modfit$finalModel
?coefficients
coefficients(modfit)
coefficients(modfit$finalModel)
plot(modfit$finalModel)
install.packages("forecast")
library(forecast)
?bats
library(lubridate)  # For year() function below
library(forecast)
dat = read.csv("~/Documents/coursera/practicalmachinelearning/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
plot(tstrain)
install.packages(lubridate)
install.packages("lubridate")
library(lubridate)  # For year() function below
library(forecast)
dat = read.csv("~/Documents/coursera/practicalmachinelearning/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
plot(tstrain)
plot(decomp(tstrain))
install.packages(quantmod)
install.packages("quantmod")
plot(decomp(tstrain))
?bats
modfit=bats(tstrain)
fore=forecast(modfit)
plot(fore)
tstest = ts(testing$visitsTumblr)
plot(tstrain)
#Fit a model using the bats() function in the forecast package to the training time series. Then forecast this model for the remaining time points. For how many of the testing points is the true value within the 95% prediction interval bounds?
modfit=bats(tstrain)
fore = forecast(modfit)
plot(fore)
accuracy(fore,tstrain)
tstest=ts(testing$visitsTumblr)
modfit=bats(tstrain)
fore=forecast(modfit)
accuracy(fore,tstrain)
fore
tstrain
accuracy(fore,testing$visitsTumblr)
acc=sum(testing$visitsTumblr<=fore$upper)/nrow(testing$visitsTumblr)
fore$upper
accuracy(fore,tstrain)
accuracy(fore,testing$visitsTumblr)
tstest = ts(testing$visitsTumblr)
plot(tstrain)
#Fit a model using the bats() function in the forecast package to the training time series. Then forecast this model for the remaining time points. For how many of the testing points is the true value within the 95% prediction interval bounds?
modfit=bats(tstrain,level=95)
fore = forecast(modfit)
plot(fore)
accuracy(fore,tstrain)
accuracy(fore,testing$visitsTumblr)
acc=sum(testing$visitsTumblr<=fore$upper)/nrow(testing$visitsTumblr)
fore$upper
testing$visitsTumblr
fore$lower[1:229]
xval  = dim(testing)[1]
modfit=bats(tstrain,level=95,h=xval)
fore = forecast(modfit)
plot(fore)
accuracy(fore,testing$visitsTumblr)
fore$lower[1:229]
modfit$x
plot.tbats(modfit$x)
plot.tbats(modfit)
length(fore$lower)
fore
modfit
accuracy(modfit)
fore
plot(fore)
str(training)
tstest = ts(testing$visitsTumblr)
plot(tstrain)
#Fit a model using the bats() function in the forecast package to the training time series. Then forecast this model for the remaining time points. For how many of the testing points is the true value within the 95% prediction interval bounds?
xval  = dim(testing)[1]
modfit=bats(tstrain,level=95,h=xval)
fore = forecast(modfit,h=length(tstest),level=c(95))
plot(fore)
accuracy(fore,testing$visitsTumblr)
sum(testing$visitsTumblr<=fore$upper)/nrow(testing)
fore
install.packages("e1071")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
#Set the seed to 325 and fit a support vector machine using the e1071 package to predict Compressive Strength using the default settings. Predict on the testing set. What is the RMSE?
set.seed(325)
library(e1071)
modfit=svm(CompressiveStrength~.,data=training)
pred=predict(model,testing)
err=sqrt(sum(pred-testing$CompressiveStrength)^2)
pred=predict(modfit,testing)
err=sqrt(sum(pred-testing$CompressiveStrength)^2)
err
err=sqrt(sum((pred-testing$CompressiveStrength)^2))
err
pred
testing$CompressiveStrength
err=sqrt(sum((pred-testing$CompressiveStrength)^2)/length(testing$CompressiveStrength))
err
qnorm(.95,mean=100,sd=10/sqrt(50))
qnorm(.95)*10+100
1.645*.04
pnorm(.0658/sqrt(500),mean=0.01,sd=0.04/sqrt(500))
pnorm(.0658/sqrt(500),mean=0.01,sd=0.04/sqrt(500),lower.tail=FALSE)
pnorm(.0658/sqrt(10),mean=0.01,sd=0.04/sqrt(10),lower.tail=FALSE)
pnorm(.0658/sqrt(500),mean=0.01,sd=0.04/sqrt(500),lower.tail=FALSE)
pnorm(.0658/sqrt(1000),mean=0.01,sd=0.04/sqrt(1000),lower.tail=FALSE)
pnorm(.0658/sqrt(100),mean=0.01,sd=0.04/sqrt(100),lower.tail=FALSE)
pnorm(.0658/sqrt(99),mean=0.01,sd=0.04/sqrt(99),lower.tail=FALSE)
pnorm(.0658/sqrt(98),mean=0.01,sd=0.04/sqrt(98),lower.tail=FALSE)
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
library(markdown)
?tabPanel
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
shiny::runApp('Documents/coursera/dataproducts/shinyapp')
library(devtools)
install_github('slidify','ramnathv')
install_github('slidifyLibraries','ramnathv')
library(slidify)
install.packages("stringr")
install.packages("stringr")
library(slidify)
setwd("~/Documents/coursera/dataproducts/slidifyshinyAppDemo/")
author("first_deck")
slidify('index.Rmd')
library(lnitr)
library(knitr)
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
